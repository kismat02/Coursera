{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      " 9453568/11490434 [=======================>......] - ETA: 0s(50000, 28, 28) (50000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6c9aae7f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from preprocessed_mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "print(X_train.shape, y_train.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten the graphs\n",
    "Converting each 28x28 pixel graph into a single array with 784 elements  \n",
    "Converting the label array to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_base(y):\n",
    "    y_base = np.zeros((y.shape[0],10))\n",
    "    for i in range(y.shape[0]):\n",
    "        y_base[i,y[i]] = 1.0\n",
    "    return y_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "\n",
    "y_train_base = convert_to_base(y_train)\n",
    "y_val_base = convert_to_base(y_val)\n",
    "y_test_base = convert_to_base(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up neural network\n",
    "Input layer: 784 neurons  \n",
    "1 hidden layer: 100 neurons  \n",
    "Output layer: 10 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_batch = 10\n",
    "num_iterations = 40000\n",
    "num_diagnostic = 200\n",
    "num_neurons = [784, 100, 10]\n",
    "num_total_layers = len(num_neurons)\n",
    "\n",
    "X_subset = tf.placeholder(dtype = 'float32', name = 'X_subset', shape=[None, 784])\n",
    "y_subset = tf.placeholder(dtype = 'float32', name = 'y_subset', shape=[None, 10])\n",
    "X_eval = tf.placeholder(dtype = 'float32', name = 'X_eval', shape=[None, 784])\n",
    "y_eval = tf.placeholder(dtype = 'float32', name = 'y_eval', shape=[None, 10])\n",
    "\n",
    "weights = []\n",
    "biases = []\n",
    "for i in range(num_total_layers-1):\n",
    "    weights.append(tf.Variable(tf.truncated_normal([num_neurons[i], num_neurons[i+1]], stddev = 0.1), trainable=True))\n",
    "    biases.append(tf.Variable(tf.truncated_normal([num_neurons[i+1]], stddev = 0.1), trainable=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network  \n",
    "NN_output: Given input x of the training set, return the network output  \n",
    "NN_loss: calculate the cross entropy loss between output and true label  \n",
    "Get_accuracy: Calculate the accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NN_output(x):\n",
    "    layer_out = x\n",
    "    for i in range(num_total_layers-1):\n",
    "        layer_out = tf.add(tf.matmul(layer_out, weights[i]), biases[i])\n",
    "        layer_out = tf.nn.sigmoid(layer_out)\n",
    "    \n",
    "    return layer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NN_loss(x, y):\n",
    "    y_output = NN_output(x)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_output, labels=y))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Get_accuracy(x,y):\n",
    "    corr_pred = tf.equal(tf.argmax(NN_output(x),1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(corr_pred, tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the tensorflow variable for training and evaluation\n",
    "loss_NN = NN_loss(X_subset,y_subset)\n",
    "train_NN = tf.train.GradientDescentOptimizer(0.5).minimize(loss_NN)\n",
    "eval_NN = Get_accuracy(X_eval, y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration step  0 , the accuracy is  0.0891 train loss is 2.30874 , test loss is  2.30951\n",
      "iteration step  200 , the accuracy is  0.7099 train loss is 1.87719 , test loss is  1.86947\n",
      "iteration step  400 , the accuracy is  0.7938 train loss is 1.74906 , test loss is  1.7416\n",
      "iteration step  600 , the accuracy is  0.8425 train loss is 1.69824 , test loss is  1.69051\n",
      "iteration step  800 , the accuracy is  0.8619 train loss is 1.66642 , test loss is  1.65847\n",
      "iteration step  1000 , the accuracy is  0.8735 train loss is 1.64483 , test loss is  1.63747\n",
      "iteration step  1200 , the accuracy is  0.8856 train loss is 1.62951 , test loss is  1.62164\n",
      "iteration step  1400 , the accuracy is  0.8905 train loss is 1.61919 , test loss is  1.61162\n",
      "iteration step  1600 , the accuracy is  0.8932 train loss is 1.60949 , test loss is  1.60185\n",
      "iteration step  1800 , the accuracy is  0.8939 train loss is 1.60281 , test loss is  1.59612\n",
      "iteration step  2000 , the accuracy is  0.8991 train loss is 1.59551 , test loss is  1.58895\n",
      "iteration step  2200 , the accuracy is  0.9043 train loss is 1.58821 , test loss is  1.58219\n",
      "iteration step  2400 , the accuracy is  0.9036 train loss is 1.5833 , test loss is  1.57765\n",
      "iteration step  2600 , the accuracy is  0.9039 train loss is 1.5808 , test loss is  1.57533\n",
      "iteration step  2800 , the accuracy is  0.9062 train loss is 1.57618 , test loss is  1.57113\n",
      "iteration step  3000 , the accuracy is  0.9103 train loss is 1.57241 , test loss is  1.56732\n",
      "iteration step  3200 , the accuracy is  0.9071 train loss is 1.57226 , test loss is  1.56757\n",
      "iteration step  3400 , the accuracy is  0.9126 train loss is 1.56881 , test loss is  1.56395\n",
      "iteration step  3600 , the accuracy is  0.9109 train loss is 1.56712 , test loss is  1.5613\n",
      "iteration step  3800 , the accuracy is  0.9161 train loss is 1.56287 , test loss is  1.55812\n",
      "iteration step  4000 , the accuracy is  0.916 train loss is 1.56087 , test loss is  1.55611\n",
      "iteration step  4200 , the accuracy is  0.9152 train loss is 1.55945 , test loss is  1.55512\n",
      "iteration step  4400 , the accuracy is  0.9174 train loss is 1.55763 , test loss is  1.55385\n",
      "iteration step  4600 , the accuracy is  0.9157 train loss is 1.55708 , test loss is  1.5539\n",
      "iteration step  4800 , the accuracy is  0.919 train loss is 1.55451 , test loss is  1.55026\n",
      "iteration step  5000 , the accuracy is  0.9184 train loss is 1.55208 , test loss is  1.54839\n",
      "iteration step  5200 , the accuracy is  0.9162 train loss is 1.55509 , test loss is  1.55114\n",
      "iteration step  5400 , the accuracy is  0.9208 train loss is 1.55075 , test loss is  1.54746\n",
      "iteration step  5600 , the accuracy is  0.9188 train loss is 1.55057 , test loss is  1.54744\n",
      "iteration step  5800 , the accuracy is  0.9226 train loss is 1.54841 , test loss is  1.54511\n",
      "iteration step  6000 , the accuracy is  0.9238 train loss is 1.54664 , test loss is  1.54297\n",
      "iteration step  6200 , the accuracy is  0.9247 train loss is 1.54529 , test loss is  1.54215\n",
      "iteration step  6400 , the accuracy is  0.9267 train loss is 1.54459 , test loss is  1.54142\n",
      "iteration step  6600 , the accuracy is  0.9247 train loss is 1.54411 , test loss is  1.54136\n",
      "iteration step  6800 , the accuracy is  0.9255 train loss is 1.54524 , test loss is  1.54202\n",
      "iteration step  7000 , the accuracy is  0.9274 train loss is 1.5416 , test loss is  1.53949\n",
      "iteration step  7200 , the accuracy is  0.925 train loss is 1.54198 , test loss is  1.53948\n",
      "iteration step  7400 , the accuracy is  0.9269 train loss is 1.54038 , test loss is  1.53791\n",
      "iteration step  7600 , the accuracy is  0.9272 train loss is 1.54048 , test loss is  1.53838\n",
      "iteration step  7800 , the accuracy is  0.9279 train loss is 1.5389 , test loss is  1.53684\n",
      "iteration step  8000 , the accuracy is  0.9281 train loss is 1.53731 , test loss is  1.53572\n",
      "iteration step  8200 , the accuracy is  0.9286 train loss is 1.53672 , test loss is  1.53517\n",
      "iteration step  8400 , the accuracy is  0.9283 train loss is 1.53642 , test loss is  1.53519\n",
      "iteration step  8600 , the accuracy is  0.9295 train loss is 1.5349 , test loss is  1.53401\n",
      "iteration step  8800 , the accuracy is  0.9263 train loss is 1.53843 , test loss is  1.53711\n",
      "iteration step  9000 , the accuracy is  0.9303 train loss is 1.53407 , test loss is  1.53312\n",
      "iteration step  9200 , the accuracy is  0.9296 train loss is 1.53338 , test loss is  1.53232\n",
      "iteration step  9400 , the accuracy is  0.9317 train loss is 1.53219 , test loss is  1.531\n",
      "iteration step  9600 , the accuracy is  0.932 train loss is 1.53178 , test loss is  1.5311\n",
      "iteration step  9800 , the accuracy is  0.9307 train loss is 1.53318 , test loss is  1.5323\n",
      "iteration step  10000 , the accuracy is  0.932 train loss is 1.5314 , test loss is  1.53065\n",
      "iteration step  10200 , the accuracy is  0.9342 train loss is 1.5298 , test loss is  1.52894\n",
      "iteration step  10400 , the accuracy is  0.9345 train loss is 1.5299 , test loss is  1.52929\n",
      "iteration step  10600 , the accuracy is  0.9338 train loss is 1.52936 , test loss is  1.52908\n",
      "iteration step  10800 , the accuracy is  0.9337 train loss is 1.52977 , test loss is  1.52903\n",
      "iteration step  11000 , the accuracy is  0.9341 train loss is 1.52881 , test loss is  1.52816\n",
      "iteration step  11200 , the accuracy is  0.9357 train loss is 1.52713 , test loss is  1.52685\n",
      "iteration step  11400 , the accuracy is  0.9359 train loss is 1.52709 , test loss is  1.52656\n",
      "iteration step  11600 , the accuracy is  0.9348 train loss is 1.52747 , test loss is  1.52678\n",
      "iteration step  11800 , the accuracy is  0.9376 train loss is 1.52553 , test loss is  1.52533\n",
      "iteration step  12000 , the accuracy is  0.9382 train loss is 1.52495 , test loss is  1.52491\n",
      "iteration step  12200 , the accuracy is  0.9372 train loss is 1.52442 , test loss is  1.52457\n",
      "iteration step  12400 , the accuracy is  0.9382 train loss is 1.52498 , test loss is  1.52519\n",
      "iteration step  12600 , the accuracy is  0.9382 train loss is 1.52443 , test loss is  1.5247\n",
      "iteration step  12800 , the accuracy is  0.9386 train loss is 1.52331 , test loss is  1.52311\n",
      "iteration step  13000 , the accuracy is  0.9393 train loss is 1.52304 , test loss is  1.52293\n",
      "iteration step  13200 , the accuracy is  0.938 train loss is 1.52384 , test loss is  1.52405\n",
      "iteration step  13400 , the accuracy is  0.9397 train loss is 1.52222 , test loss is  1.52285\n",
      "iteration step  13600 , the accuracy is  0.9396 train loss is 1.52199 , test loss is  1.52246\n",
      "iteration step  13800 , the accuracy is  0.9399 train loss is 1.52257 , test loss is  1.52257\n",
      "iteration step  14000 , the accuracy is  0.9406 train loss is 1.52066 , test loss is  1.52123\n",
      "iteration step  14200 , the accuracy is  0.9386 train loss is 1.52092 , test loss is  1.52148\n",
      "iteration step  14400 , the accuracy is  0.9385 train loss is 1.52054 , test loss is  1.52121\n",
      "iteration step  14600 , the accuracy is  0.9376 train loss is 1.52129 , test loss is  1.52196\n",
      "iteration step  14800 , the accuracy is  0.941 train loss is 1.51943 , test loss is  1.52023\n",
      "iteration step  15000 , the accuracy is  0.94 train loss is 1.52018 , test loss is  1.52097\n",
      "iteration step  15200 , the accuracy is  0.9415 train loss is 1.51954 , test loss is  1.52011\n",
      "iteration step  15400 , the accuracy is  0.9401 train loss is 1.51942 , test loss is  1.5205\n",
      "iteration step  15600 , the accuracy is  0.9417 train loss is 1.51912 , test loss is  1.51951\n",
      "iteration step  15800 , the accuracy is  0.9424 train loss is 1.51838 , test loss is  1.51915\n",
      "iteration step  16000 , the accuracy is  0.9424 train loss is 1.51794 , test loss is  1.51881\n",
      "iteration step  16200 , the accuracy is  0.9419 train loss is 1.51798 , test loss is  1.51838\n",
      "iteration step  16400 , the accuracy is  0.9411 train loss is 1.51794 , test loss is  1.51883\n",
      "iteration step  16600 , the accuracy is  0.9434 train loss is 1.51665 , test loss is  1.51765\n",
      "iteration step  16800 , the accuracy is  0.9444 train loss is 1.51613 , test loss is  1.517\n",
      "iteration step  17000 , the accuracy is  0.9435 train loss is 1.51686 , test loss is  1.51731\n",
      "iteration step  17200 , the accuracy is  0.9447 train loss is 1.51609 , test loss is  1.51704\n",
      "iteration step  17400 , the accuracy is  0.9441 train loss is 1.51743 , test loss is  1.51858\n",
      "iteration step  17600 , the accuracy is  0.9459 train loss is 1.51565 , test loss is  1.51676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration step  17800 , the accuracy is  0.9445 train loss is 1.51549 , test loss is  1.51699\n",
      "iteration step  18000 , the accuracy is  0.9427 train loss is 1.51628 , test loss is  1.51786\n",
      "iteration step  18200 , the accuracy is  0.9456 train loss is 1.51477 , test loss is  1.51598\n",
      "iteration step  18400 , the accuracy is  0.9451 train loss is 1.51557 , test loss is  1.51684\n",
      "iteration step  18600 , the accuracy is  0.945 train loss is 1.51473 , test loss is  1.5162\n",
      "iteration step  18800 , the accuracy is  0.9454 train loss is 1.51328 , test loss is  1.5151\n",
      "iteration step  19000 , the accuracy is  0.9459 train loss is 1.51359 , test loss is  1.51548\n",
      "iteration step  19200 , the accuracy is  0.9469 train loss is 1.51278 , test loss is  1.51491\n",
      "iteration step  19400 , the accuracy is  0.947 train loss is 1.51307 , test loss is  1.51494\n",
      "iteration step  19600 , the accuracy is  0.9469 train loss is 1.5128 , test loss is  1.51454\n",
      "iteration step  19800 , the accuracy is  0.9461 train loss is 1.5135 , test loss is  1.51533\n",
      "iteration step  20000 , the accuracy is  0.9472 train loss is 1.51206 , test loss is  1.51425\n",
      "iteration step  20200 , the accuracy is  0.9482 train loss is 1.51197 , test loss is  1.51365\n",
      "iteration step  20400 , the accuracy is  0.9472 train loss is 1.51252 , test loss is  1.51454\n",
      "iteration step  20600 , the accuracy is  0.9472 train loss is 1.51143 , test loss is  1.51392\n",
      "iteration step  20800 , the accuracy is  0.9476 train loss is 1.5112 , test loss is  1.51358\n",
      "iteration step  21000 , the accuracy is  0.9481 train loss is 1.51187 , test loss is  1.51381\n",
      "iteration step  21200 , the accuracy is  0.947 train loss is 1.51114 , test loss is  1.51323\n",
      "iteration step  21400 , the accuracy is  0.9491 train loss is 1.51053 , test loss is  1.51231\n",
      "iteration step  21600 , the accuracy is  0.9485 train loss is 1.51087 , test loss is  1.51305\n",
      "iteration step  21800 , the accuracy is  0.948 train loss is 1.51111 , test loss is  1.51325\n",
      "iteration step  22000 , the accuracy is  0.9492 train loss is 1.51039 , test loss is  1.51253\n",
      "iteration step  22200 , the accuracy is  0.9482 train loss is 1.51015 , test loss is  1.51269\n",
      "iteration step  22400 , the accuracy is  0.9479 train loss is 1.5097 , test loss is  1.51208\n",
      "iteration step  22600 , the accuracy is  0.9489 train loss is 1.50943 , test loss is  1.51196\n",
      "iteration step  22800 , the accuracy is  0.9485 train loss is 1.50917 , test loss is  1.5116\n",
      "iteration step  23000 , the accuracy is  0.9485 train loss is 1.50931 , test loss is  1.51198\n",
      "iteration step  23200 , the accuracy is  0.9492 train loss is 1.50925 , test loss is  1.51154\n",
      "iteration step  23400 , the accuracy is  0.9495 train loss is 1.50874 , test loss is  1.51176\n",
      "iteration step  23600 , the accuracy is  0.9482 train loss is 1.50956 , test loss is  1.51191\n",
      "iteration step  23800 , the accuracy is  0.9486 train loss is 1.5084 , test loss is  1.51099\n",
      "iteration step  24000 , the accuracy is  0.9493 train loss is 1.50806 , test loss is  1.51084\n",
      "iteration step  24200 , the accuracy is  0.9512 train loss is 1.5077 , test loss is  1.51003\n",
      "iteration step  24400 , the accuracy is  0.951 train loss is 1.50755 , test loss is  1.51068\n",
      "iteration step  24600 , the accuracy is  0.9496 train loss is 1.50794 , test loss is  1.51073\n",
      "iteration step  24800 , the accuracy is  0.9477 train loss is 1.50877 , test loss is  1.51114\n",
      "iteration step  25000 , the accuracy is  0.9507 train loss is 1.50686 , test loss is  1.51005\n",
      "iteration step  25200 , the accuracy is  0.9497 train loss is 1.50736 , test loss is  1.51093\n",
      "iteration step  25400 , the accuracy is  0.9521 train loss is 1.50665 , test loss is  1.50982\n",
      "iteration step  25600 , the accuracy is  0.9518 train loss is 1.50678 , test loss is  1.50991\n",
      "iteration step  25800 , the accuracy is  0.9514 train loss is 1.5068 , test loss is  1.50991\n",
      "iteration step  26000 , the accuracy is  0.9506 train loss is 1.50617 , test loss is  1.50961\n",
      "iteration step  26200 , the accuracy is  0.9516 train loss is 1.50646 , test loss is  1.50912\n",
      "iteration step  26400 , the accuracy is  0.951 train loss is 1.50616 , test loss is  1.5093\n",
      "iteration step  26600 , the accuracy is  0.9516 train loss is 1.50588 , test loss is  1.50879\n",
      "iteration step  26800 , the accuracy is  0.9527 train loss is 1.50504 , test loss is  1.50835\n",
      "iteration step  27000 , the accuracy is  0.9521 train loss is 1.50561 , test loss is  1.50908\n",
      "iteration step  27200 , the accuracy is  0.9504 train loss is 1.5052 , test loss is  1.50944\n",
      "iteration step  27400 , the accuracy is  0.9532 train loss is 1.50507 , test loss is  1.50821\n",
      "iteration step  27600 , the accuracy is  0.9527 train loss is 1.50494 , test loss is  1.50868\n",
      "iteration step  27800 , the accuracy is  0.9521 train loss is 1.5046 , test loss is  1.50842\n",
      "iteration step  28000 , the accuracy is  0.9524 train loss is 1.50413 , test loss is  1.50815\n",
      "iteration step  28200 , the accuracy is  0.9523 train loss is 1.50406 , test loss is  1.50755\n",
      "iteration step  28400 , the accuracy is  0.9536 train loss is 1.50396 , test loss is  1.50763\n",
      "iteration step  28600 , the accuracy is  0.9523 train loss is 1.50451 , test loss is  1.50825\n",
      "iteration step  28800 , the accuracy is  0.953 train loss is 1.50444 , test loss is  1.50772\n",
      "iteration step  29000 , the accuracy is  0.9538 train loss is 1.50431 , test loss is  1.50755\n",
      "iteration step  29200 , the accuracy is  0.954 train loss is 1.50317 , test loss is  1.50706\n",
      "iteration step  29400 , the accuracy is  0.9536 train loss is 1.50373 , test loss is  1.50699\n",
      "iteration step  29600 , the accuracy is  0.9541 train loss is 1.50424 , test loss is  1.50778\n",
      "iteration step  29800 , the accuracy is  0.9536 train loss is 1.50289 , test loss is  1.50665\n",
      "iteration step  30000 , the accuracy is  0.9538 train loss is 1.50246 , test loss is  1.50657\n",
      "iteration step  30200 , the accuracy is  0.9532 train loss is 1.5032 , test loss is  1.50717\n",
      "iteration step  30400 , the accuracy is  0.9545 train loss is 1.50252 , test loss is  1.50679\n",
      "iteration step  30600 , the accuracy is  0.9544 train loss is 1.50206 , test loss is  1.50627\n",
      "iteration step  30800 , the accuracy is  0.954 train loss is 1.50242 , test loss is  1.50629\n",
      "iteration step  31000 , the accuracy is  0.9544 train loss is 1.5016 , test loss is  1.50548\n",
      "iteration step  31200 , the accuracy is  0.9547 train loss is 1.50182 , test loss is  1.50607\n",
      "iteration step  31400 , the accuracy is  0.9531 train loss is 1.50243 , test loss is  1.50709\n",
      "iteration step  31600 , the accuracy is  0.9562 train loss is 1.50149 , test loss is  1.50584\n",
      "iteration step  31800 , the accuracy is  0.955 train loss is 1.50187 , test loss is  1.50578\n",
      "iteration step  32000 , the accuracy is  0.9559 train loss is 1.5024 , test loss is  1.50648\n",
      "iteration step  32200 , the accuracy is  0.9548 train loss is 1.50175 , test loss is  1.50606\n",
      "iteration step  32400 , the accuracy is  0.9561 train loss is 1.50084 , test loss is  1.50525\n",
      "iteration step  32600 , the accuracy is  0.9543 train loss is 1.50136 , test loss is  1.50566\n",
      "iteration step  32800 , the accuracy is  0.9555 train loss is 1.50082 , test loss is  1.50547\n",
      "iteration step  33000 , the accuracy is  0.9564 train loss is 1.50071 , test loss is  1.50514\n",
      "iteration step  33200 , the accuracy is  0.9561 train loss is 1.50071 , test loss is  1.50555\n",
      "iteration step  33400 , the accuracy is  0.9569 train loss is 1.50066 , test loss is  1.50489\n",
      "iteration step  33600 , the accuracy is  0.9584 train loss is 1.50054 , test loss is  1.50488\n",
      "iteration step  33800 , the accuracy is  0.9555 train loss is 1.50055 , test loss is  1.50494\n",
      "iteration step  34000 , the accuracy is  0.9557 train loss is 1.5004 , test loss is  1.50539\n",
      "iteration step  34200 , the accuracy is  0.9582 train loss is 1.50012 , test loss is  1.50453\n",
      "iteration step  34400 , the accuracy is  0.9566 train loss is 1.50033 , test loss is  1.50477\n",
      "iteration step  34600 , the accuracy is  0.9584 train loss is 1.49942 , test loss is  1.5037\n",
      "iteration step  34800 , the accuracy is  0.9584 train loss is 1.49922 , test loss is  1.50384\n",
      "iteration step  35000 , the accuracy is  0.9573 train loss is 1.49934 , test loss is  1.50383\n",
      "iteration step  35200 , the accuracy is  0.9572 train loss is 1.49973 , test loss is  1.5041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration step  35400 , the accuracy is  0.9585 train loss is 1.49915 , test loss is  1.50355\n",
      "iteration step  35600 , the accuracy is  0.9575 train loss is 1.49867 , test loss is  1.50361\n",
      "iteration step  35800 , the accuracy is  0.9577 train loss is 1.50028 , test loss is  1.50527\n",
      "iteration step  36000 , the accuracy is  0.9578 train loss is 1.49887 , test loss is  1.50408\n",
      "iteration step  36200 , the accuracy is  0.9577 train loss is 1.49861 , test loss is  1.50358\n",
      "iteration step  36400 , the accuracy is  0.958 train loss is 1.49896 , test loss is  1.50397\n",
      "iteration step  36600 , the accuracy is  0.9582 train loss is 1.49805 , test loss is  1.50323\n",
      "iteration step  36800 , the accuracy is  0.9573 train loss is 1.49848 , test loss is  1.50392\n",
      "iteration step  37000 , the accuracy is  0.9562 train loss is 1.49853 , test loss is  1.50407\n",
      "iteration step  37200 , the accuracy is  0.9586 train loss is 1.49813 , test loss is  1.50304\n",
      "iteration step  37400 , the accuracy is  0.9586 train loss is 1.4982 , test loss is  1.50291\n",
      "iteration step  37600 , the accuracy is  0.9569 train loss is 1.49817 , test loss is  1.5039\n",
      "iteration step  37800 , the accuracy is  0.9577 train loss is 1.49783 , test loss is  1.50268\n",
      "iteration step  38000 , the accuracy is  0.9588 train loss is 1.4977 , test loss is  1.50272\n",
      "iteration step  38200 , the accuracy is  0.959 train loss is 1.49773 , test loss is  1.50263\n",
      "iteration step  38400 , the accuracy is  0.9599 train loss is 1.4974 , test loss is  1.50221\n",
      "iteration step  38600 , the accuracy is  0.9587 train loss is 1.49802 , test loss is  1.50243\n",
      "iteration step  38800 , the accuracy is  0.9589 train loss is 1.49705 , test loss is  1.50198\n",
      "iteration step  39000 , the accuracy is  0.9583 train loss is 1.49696 , test loss is  1.50221\n",
      "iteration step  39200 , the accuracy is  0.9587 train loss is 1.49716 , test loss is  1.5017\n",
      "iteration step  39400 , the accuracy is  0.9597 train loss is 1.49693 , test loss is  1.50203\n",
      "iteration step  39600 , the accuracy is  0.9597 train loss is 1.49669 , test loss is  1.50207\n",
      "iteration step  39800 , the accuracy is  0.9607 train loss is 1.49655 , test loss is  1.50179\n",
      "Total time is 189.1813142299652 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run the training step and evaluate every num_diagnostic steps\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "accuracy= []\n",
    "iter_num = []\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    \n",
    "    ind = np.random.choice(X_train.shape[0], mini_batch)\n",
    "    sess.run((train_NN, loss_NN), feed_dict = {X_subset: X_train[ind,:], y_subset: y_train_base[ind,:]})\n",
    "    \n",
    "    if(i % num_diagnostic == 0):\n",
    "        iter_num.append(i)\n",
    "        train_loss.append(sess.run(loss_NN, feed_dict = {X_subset: X_train, y_subset: y_train_base}))\n",
    "        test_loss.append(sess.run(loss_NN, feed_dict = {X_subset: X_test, y_subset: y_test_base}))\n",
    "        accuracy.append(sess.run(eval_NN, feed_dict = {X_eval: X_test, y_eval: y_test_base}))\n",
    "        print('iteration step ', i, ', the accuracy is ', accuracy[-1], \\\n",
    "              'train loss is', train_loss[-1],', test loss is ', test_loss[-1])\n",
    "        \n",
    "end = time.time()\n",
    "\n",
    "# print the time needed for training and evaluation\n",
    "print('Total time is', end - start, 'seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAGKCAYAAADE5DToAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiIiJp538Bo7s7WGsl0QsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6c958a1080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the loss and accuracy vs. iteration number\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (14,6))\n",
    "plt.rc('font', size= 12)\n",
    "plt.subplot(121)\n",
    "plt.plot(iter_num, train_loss, 'b')\n",
    "plt.plot(iter_num, test_loss, 'r')\n",
    "plt.legend(['train loss', 'test loss'])\n",
    "plt.xlabel('iteration num')\n",
    "plt.title('Loss vs. iteration number')\n",
    "plt.subplot(122)\n",
    "plt.plot(iter_num, accuracy)\n",
    "plt.xlabel('iteration num')\n",
    "plt.title('Accuracy vs. iteration number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
